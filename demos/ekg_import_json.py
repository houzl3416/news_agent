#!/usr/bin/env python3
"""
EKG JSON æ•°æ®å¯¼å…¥å·¥å…·

æ”¯æŒä» JSON æ–‡ä»¶å¯¼å…¥äº‹ä»¶ã€å£°æ˜ã€ä¿¡æºç­‰æ•°æ®åˆ° EKG æ•°æ®åº“ã€‚

è¿è¡Œæ–¹å¼:
    # ä»å•ä¸ª JSON æ–‡ä»¶å¯¼å…¥
    python demos/ekg_import_json.py --file data.json

    # ä»ç›®å½•æ‰¹é‡å¯¼å…¥æ‰€æœ‰ JSON æ–‡ä»¶
    python demos/ekg_import_json.py --dir ./data/

    # æŒ‡å®šæ•°æ®åº“è·¯å¾„
    python demos/ekg_import_json.py --file data.json --db my_ekg.db

    # æ˜¾ç¤º JSON æ ¼å¼ç¤ºä¾‹
    python demos/ekg_import_json.py --example
"""
import sys
import json
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.ekg.repository import EKGRepository
from src.ekg.models import SourceType, EventStatus, ClaimStatus, Base

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import StaticPool


class EKGJSONImporter:
    """EKG JSON æ•°æ®å¯¼å…¥å™¨"""

    def __init__(self, db_path: str = "demos/ekg_demo.db"):
        """åˆå§‹åŒ–å¯¼å…¥å™¨"""
        self.db_path = db_path

        # ç›´æ¥åˆ›å»º SQLAlchemy å¼•æ“å’Œä¼šè¯
        self.engine = create_engine(
            f"sqlite:///{db_path}",
            connect_args={"check_same_thread": False},
            poolclass=StaticPool
        )

        # åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        Base.metadata.create_all(bind=self.engine)

        # åˆ›å»ºä¼šè¯
        SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
        self.session = SessionLocal()
        self.repo = EKGRepository(self.session)
        self.stats = {
            "sources": 0,
            "events": 0,
            "claims": 0,
            "entities": 0,
            "artifacts": 0,
            "refutations": 0,
            "errors": 0
        }

    def import_from_file(self, file_path: str) -> bool:
        """
        ä» JSON æ–‡ä»¶å¯¼å…¥æ•°æ®

        Args:
            file_path: JSON æ–‡ä»¶è·¯å¾„

        Returns:
            æ˜¯å¦å¯¼å…¥æˆåŠŸ
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            print(f"ğŸ“‚ æ­£åœ¨å¯¼å…¥: {file_path}")
            return self.import_data(data)

        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return False
        except json.JSONDecodeError as e:
            print(f"âŒ JSON æ ¼å¼é”™è¯¯: {e}")
            return False
        except Exception as e:
            print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
            return False

    def import_from_directory(self, dir_path: str) -> int:
        """
        ä»ç›®å½•æ‰¹é‡å¯¼å…¥æ‰€æœ‰ JSON æ–‡ä»¶

        Args:
            dir_path: ç›®å½•è·¯å¾„

        Returns:
            æˆåŠŸå¯¼å…¥çš„æ–‡ä»¶æ•°
        """
        directory = Path(dir_path)
        if not directory.exists() or not directory.is_dir():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {dir_path}")
            return 0

        json_files = list(directory.glob("*.json"))
        if not json_files:
            print(f"âš ï¸  ç›®å½•ä¸­æ²¡æœ‰ JSON æ–‡ä»¶: {dir_path}")
            return 0

        success_count = 0
        print(f"ğŸ“ æ‰¾åˆ° {len(json_files)} ä¸ª JSON æ–‡ä»¶")
        print("=" * 80)

        for json_file in json_files:
            if self.import_from_file(str(json_file)):
                success_count += 1
            print()

        return success_count

    def import_data(self, data: Dict[str, Any]) -> bool:
        """
        å¯¼å…¥ JSON æ•°æ®

        Args:
            data: JSON æ•°æ®å­—å…¸

        Returns:
            æ˜¯å¦å¯¼å…¥æˆåŠŸ
        """
        try:
            # 1. å¯¼å…¥ä¿¡æº
            if "sources" in data:
                self._import_sources(data["sources"])

            # 2. å¯¼å…¥äº‹ä»¶
            if "events" in data:
                self._import_events(data["events"])

            # 3. å¯¼å…¥å£°æ˜
            if "claims" in data:
                self._import_claims(data["claims"])

            # 4. å¯¼å…¥å®ä½“
            if "entities" in data:
                self._import_entities(data["entities"])

            # 5. å¯¼å…¥ç‰©æ–™
            if "artifacts" in data:
                self._import_artifacts(data["artifacts"])

            # 6. å¯¼å…¥è¯ä¼ªå…³ç³»
            if "refutations" in data:
                self._import_refutations(data["refutations"])

            print(f"âœ… å¯¼å…¥æˆåŠŸ")
            self._print_stats()
            return True

        except Exception as e:
            print(f"âŒ å¯¼å…¥è¿‡ç¨‹å‡ºé”™: {e}")
            self.stats["errors"] += 1
            return False

    def _import_sources(self, sources: List[Dict[str, Any]]):
        """å¯¼å…¥ä¿¡æº"""
        for source_data in sources:
            try:
                source = self.repo.find_or_create_source(
                    name=source_data["name"],
                    source_type=SourceType(source_data.get("type", "unknown")),
                    url=source_data.get("url"),
                    description=source_data.get("description"),
                    extra_data=source_data.get("extra_data", {})
                )
                self.stats["sources"] += 1
                print(f"  âœ“ ä¿¡æº: {source.name}")
            except Exception as e:
                print(f"  âœ— ä¿¡æºå¯¼å…¥å¤±è´¥ ({source_data.get('name', 'unknown')}): {e}")
                self.stats["errors"] += 1

    def _import_events(self, events: List[Dict[str, Any]]):
        """å¯¼å…¥äº‹ä»¶"""
        for event_data in events:
            try:
                event = self.repo.create_event(
                    event_id=event_data["id"],
                    title=event_data["title"],
                    description=event_data.get("description"),
                    status=EventStatus(event_data.get("status", "developing")),
                    extra_data=event_data.get("extra_data", {})
                )
                self.stats["events"] += 1
                print(f"  âœ“ äº‹ä»¶: {event.id} - {event.title}")
            except Exception as e:
                print(f"  âœ— äº‹ä»¶å¯¼å…¥å¤±è´¥ ({event_data.get('id', 'unknown')}): {e}")
                self.stats["errors"] += 1

    def _import_claims(self, claims: List[Dict[str, Any]]):
        """å¯¼å…¥å£°æ˜"""
        for claim_data in claims:
            try:
                # å…ˆæŸ¥æ‰¾ä¿¡æºIDï¼ˆå¦‚æœæä¾›çš„æ˜¯åç§°ï¼‰
                source_id = claim_data.get("source_id")
                if not source_id and "source_name" in claim_data:
                    source = self.repo.get_source_by_name(claim_data["source_name"])
                    if source:
                        source_id = source.id

                if not source_id:
                    print(f"  âœ— å£°æ˜å¯¼å…¥å¤±è´¥: æ‰¾ä¸åˆ°ä¿¡æº")
                    self.stats["errors"] += 1
                    continue

                claim = self.repo.create_claim(
                    text=claim_data["text"],
                    source_id=source_id,
                    event_id=claim_data.get("event_id"),
                    status=ClaimStatus(claim_data.get("status", "pending")),
                    claim_type=claim_data.get("claim_type"),
                    verification_result=claim_data.get("verification_result", {}),
                    extra_data=claim_data.get("extra_data", {})
                )
                self.stats["claims"] += 1
                print(f"  âœ“ å£°æ˜: {claim.text[:50]}...")
            except Exception as e:
                print(f"  âœ— å£°æ˜å¯¼å…¥å¤±è´¥: {e}")
                self.stats["errors"] += 1

    def _import_entities(self, entities: List[Dict[str, Any]]):
        """å¯¼å…¥å®ä½“"""
        for entity_data in entities:
            try:
                entity = self.repo.find_or_create_entity(
                    name=entity_data["name"],
                    entity_type=entity_data["type"],
                    description=entity_data.get("description"),
                    extra_data=entity_data.get("extra_data", {})
                )
                self.stats["entities"] += 1
                print(f"  âœ“ å®ä½“: {entity.name} ({entity.type})")
            except Exception as e:
                print(f"  âœ— å®ä½“å¯¼å…¥å¤±è´¥ ({entity_data.get('name', 'unknown')}): {e}")
                self.stats["errors"] += 1

    def _import_artifacts(self, artifacts: List[Dict[str, Any]]):
        """å¯¼å…¥ç‰©æ–™"""
        for artifact_data in artifacts:
            try:
                # ç‰©æ–™éœ€è¦ç›´æ¥åˆ›å»ºï¼Œå› ä¸ºæ²¡æœ‰ find_or_create æ–¹æ³•
                # ç›´æ¥ä½¿ç”¨ session åˆ›å»º
                from src.ekg.models import Artifact
                artifact = Artifact(
                    type=artifact_data["type"],
                    url=artifact_data.get("url"),
                    content_hash=artifact_data.get("hash"),
                    content=artifact_data.get("content"),
                    extra_data=artifact_data.get("extra_data", {})
                )
                # claim_id ä¸æ˜¯ Artifact çš„å­—æ®µï¼Œå­˜å‚¨åœ¨ extra_data ä¸­
                if "claim_id" in artifact_data:
                    artifact.extra_data["claim_id"] = artifact_data["claim_id"]

                self.session.add(artifact)
                self.session.commit()
                self.stats["artifacts"] += 1
                print(f"  âœ“ ç‰©æ–™: {artifact.type} - {artifact.url[:50] if artifact.url else 'N/A'}...")
            except Exception as e:
                self.session.rollback()
                print(f"  âœ— ç‰©æ–™å¯¼å…¥å¤±è´¥: {e}")
                self.stats["errors"] += 1

    def _import_refutations(self, refutations: List[Dict[str, Any]]):
        """å¯¼å…¥è¯ä¼ªå…³ç³»"""
        for refutation_data in refutations:
            try:
                self.repo.create_claim_refutation(
                    refuting_claim_id=refutation_data["refuting_claim_id"],
                    refuted_claim_id=refutation_data["refuted_claim_id"],
                    confidence=refutation_data.get("confidence", 1.0),
                    evidence=refutation_data.get("evidence", {})
                )
                self.stats["refutations"] += 1
                print(f"  âœ“ è¯ä¼ªå…³ç³»: {refutation_data['refuting_claim_id']} -> {refutation_data['refuted_claim_id']}")
            except Exception as e:
                print(f"  âœ— è¯ä¼ªå…³ç³»å¯¼å…¥å¤±è´¥: {e}")
                self.stats["errors"] += 1

    def _print_stats(self):
        """æ‰“å°å¯¼å…¥ç»Ÿè®¡"""
        print("\n" + "=" * 80)
        print("ğŸ“Š å¯¼å…¥ç»Ÿè®¡")
        print("=" * 80)
        print(f"  ä¿¡æºæ•°: {self.stats['sources']}")
        print(f"  äº‹ä»¶æ•°: {self.stats['events']}")
        print(f"  å£°æ˜æ•°: {self.stats['claims']}")
        print(f"  å®ä½“æ•°: {self.stats['entities']}")
        print(f"  ç‰©æ–™æ•°: {self.stats['artifacts']}")
        print(f"  è¯ä¼ªå…³ç³»æ•°: {self.stats['refutations']}")
        if self.stats['errors'] > 0:
            print(f"  âŒ é”™è¯¯æ•°: {self.stats['errors']}")
        print("=" * 80)

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.session:
            self.session.close()
        if self.engine:
            self.engine.dispose()


def show_example():
    """æ˜¾ç¤º JSON æ ¼å¼ç¤ºä¾‹"""
    example = {
        "sources": [
            {
                "name": "æ–°åç¤¾",
                "type": "official_media",
                "url": "https://www.xinhuanet.com",
                "description": "ä¸­å›½å®˜æ–¹é€šè®¯ç¤¾",
                "extra_data": {
                    "country": "China",
                    "founded": "1931"
                }
            },
            {
                "name": "@TechNews",
                "type": "social_media",
                "url": "https://twitter.com/technews",
                "description": "ç§‘æŠ€æ–°é—»ç¤¾äº¤åª’ä½“è´¦å·",
                "extra_data": {
                    "platform": "Twitter",
                    "followers": 50000
                }
            }
        ],
        "events": [
            {
                "id": "E-DEMO-001",
                "title": "æŸå…¬å¸å‘å¸ƒæ–°äº§å“",
                "description": "æŸç§‘æŠ€å…¬å¸å®£å¸ƒå‘å¸ƒæ–°äº§å“",
                "status": "developing",
                "extra_data": {
                    "category": "technology",
                    "impact": "high"
                }
            }
        ],
        "claims": [
            {
                "text": "è¯¥å…¬å¸å°†äºä¸‹æœˆå‘å¸ƒæ–°äº§å“",
                "source_name": "@TechNews",
                "event_id": "E-DEMO-001",
                "status": "pending",
                "claim_type": "temporal",
                "verification_result": {},
                "extra_data": {
                    "confidence": 0.8
                }
            },
            {
                "text": "å…¬å¸å®˜æ–¹ç¡®è®¤å°†å‘å¸ƒæ–°äº§å“",
                "source_name": "æ–°åç¤¾",
                "event_id": "E-DEMO-001",
                "status": "verified",
                "claim_type": "factual",
                "verification_result": {
                    "method": "official_statement",
                    "verified_at": "2024-01-15"
                },
                "extra_data": {}
            }
        ],
        "entities": [
            {
                "name": "æŸç§‘æŠ€å…¬å¸",
                "type": "organization",
                "description": "ä¸€å®¶çŸ¥åç§‘æŠ€å…¬å¸",
                "extra_data": {
                    "industry": "technology",
                    "founded": "2000"
                }
            }
        ],
        "artifacts": [
            {
                "type": "image",
                "url": "https://example.com/product_image.jpg",
                "claim_id": 1,
                "hash": "abc123def456",
                "extra_data": {
                    "width": 1920,
                    "height": 1080
                }
            }
        ],
        "refutations": [
            {
                "refuting_claim_id": 2,
                "refuted_claim_id": 1,
                "confidence": 0.95,
                "evidence": {
                    "source": "official_statement",
                    "verified_by": "æ–°åç¤¾"
                }
            }
        ]
    }

    print("=" * 80)
    print("ğŸ“‹ EKG JSON æ•°æ®æ ¼å¼ç¤ºä¾‹")
    print("=" * 80)
    print()
    print(json.dumps(example, indent=2, ensure_ascii=False))
    print()
    print("=" * 80)
    print("ğŸ“ å­—æ®µè¯´æ˜")
    print("=" * 80)
    print()
    print("sources (ä¿¡æº):")
    print("  - name: ä¿¡æºåç§° (å¿…å¡«)")
    print("  - type: ä¿¡æºç±»å‹ (official_media/social_media/news_outlet/blog/forum/anonymous/unknown)")
    print("  - url: ä¿¡æºURL (å¯é€‰)")
    print("  - description: æè¿° (å¯é€‰)")
    print("  - extra_data: é¢å¤–æ•°æ® (å¯é€‰)")
    print()
    print("events (äº‹ä»¶):")
    print("  - id: äº‹ä»¶ID (å¿…å¡«)")
    print("  - title: äº‹ä»¶æ ‡é¢˜ (å¿…å¡«)")
    print("  - description: äº‹ä»¶æè¿° (å¯é€‰)")
    print("  - status: äº‹ä»¶çŠ¶æ€ (developing/investigated/verified/refuted)")
    print("  - extra_data: é¢å¤–æ•°æ® (å¯é€‰)")
    print()
    print("claims (å£°æ˜):")
    print("  - text: å£°æ˜å†…å®¹ (å¿…å¡«)")
    print("  - source_id: ä¿¡æºID (å¯é€‰ï¼Œä¸source_nameäºŒé€‰ä¸€)")
    print("  - source_name: ä¿¡æºåç§° (å¯é€‰ï¼Œä¸source_idäºŒé€‰ä¸€)")
    print("  - event_id: å…³è”äº‹ä»¶ID (å¯é€‰)")
    print("  - status: å£°æ˜çŠ¶æ€ (pending/verified/refuted/unverifiable)")
    print("  - claim_type: å£°æ˜ç±»å‹ (å¯é€‰)")
    print("  - verification_result: æ ¸æŸ¥ç»“æœ (å¯é€‰)")
    print("  - extra_data: é¢å¤–æ•°æ® (å¯é€‰)")
    print()
    print("entities (å®ä½“):")
    print("  - name: å®ä½“åç§° (å¿…å¡«)")
    print("  - type: å®ä½“ç±»å‹ (person/organization/locationç­‰)")
    print("  - description: æè¿° (å¯é€‰)")
    print("  - extra_data: é¢å¤–æ•°æ® (å¯é€‰)")
    print()
    print("artifacts (ç‰©æ–™):")
    print("  - type: ç‰©æ–™ç±»å‹ (image/video/documentç­‰)")
    print("  - url: ç‰©æ–™URL (å¿…å¡«)")
    print("  - claim_id: å…³è”å£°æ˜ID (å¯é€‰)")
    print("  - hash: æ–‡ä»¶å“ˆå¸Œå€¼ (å¯é€‰)")
    print("  - extra_data: é¢å¤–æ•°æ® (å¯é€‰)")
    print()
    print("refutations (è¯ä¼ªå…³ç³»):")
    print("  - refuting_claim_id: è¯ä¼ªæ–¹å£°æ˜ID (å¿…å¡«)")
    print("  - refuted_claim_id: è¢«è¯ä¼ªæ–¹å£°æ˜ID (å¿…å¡«)")
    print("  - confidence: ç½®ä¿¡åº¦ (0-1ä¹‹é—´ï¼Œå¯é€‰ï¼Œé»˜è®¤1.0)")
    print("  - evidence: è¯æ® (å¯é€‰)")
    print()
    print("=" * 80)
    print("ğŸ’¡ æç¤º:")
    print("  1. ä½ å¯ä»¥åªåŒ…å«éœ€è¦çš„éƒ¨åˆ†ï¼Œä¸éœ€è¦å…¨éƒ¨å­—æ®µ")
    print("  2. å»ºè®®å…ˆå¯¼å…¥ä¿¡æºï¼Œå†å¯¼å…¥äº‹ä»¶å’Œå£°æ˜")
    print("  3. å£°æ˜ä¸­å¯ä»¥ä½¿ç”¨ source_name ä»£æ›¿ source_id")
    print("  4. æ‰€æœ‰æ—¥æœŸæ—¶é—´ä½¿ç”¨ ISO 8601 æ ¼å¼")
    print("=" * 80)


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description="EKG JSON æ•°æ®å¯¼å…¥å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æ˜¾ç¤º JSON æ ¼å¼ç¤ºä¾‹
  python demos/ekg_import_json.py --example

  # ä»å•ä¸ªæ–‡ä»¶å¯¼å…¥
  python demos/ekg_import_json.py --file data.json

  # ä»ç›®å½•æ‰¹é‡å¯¼å…¥
  python demos/ekg_import_json.py --dir ./data/

  # æŒ‡å®šæ•°æ®åº“
  python demos/ekg_import_json.py --file data.json --db my_ekg.db
        """
    )

    parser.add_argument("--file", type=str, help="JSON æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--dir", type=str, help="åŒ…å« JSON æ–‡ä»¶çš„ç›®å½•")
    parser.add_argument("--db", type=str, default="demos/ekg_demo.db", help="æ•°æ®åº“æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--example", action="store_true", help="æ˜¾ç¤º JSON æ ¼å¼ç¤ºä¾‹")

    args = parser.parse_args()

    # æ˜¾ç¤ºç¤ºä¾‹
    if args.example:
        show_example()
        sys.exit(0)

    # æ£€æŸ¥å‚æ•°
    if not args.file and not args.dir:
        parser.print_help()
        sys.exit(0)

    # æ‰§è¡Œå¯¼å…¥
    try:
        importer = EKGJSONImporter(args.db)

        if args.file:
            success = importer.import_from_file(args.file)
            sys.exit(0 if success else 1)

        if args.dir:
            count = importer.import_from_directory(args.dir)
            print(f"\nâœ… æˆåŠŸå¯¼å…¥ {count} ä¸ªæ–‡ä»¶")
            sys.exit(0 if count > 0 else 1)

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    finally:
        if 'importer' in locals():
            importer.close()


if __name__ == "__main__":
    main()
